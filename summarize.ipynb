{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lpVdHQ-KfQf",
        "outputId": "b0f73951-cbea-4763-eafc-89907a515688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第一次请求成功，获取到 30 个仓库信息\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 60 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 90 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 120 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 150 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 180 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 210 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 240 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 270 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 300 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 330 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 360 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 390 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 420 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 450 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 480 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 510 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 540 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 570 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 600 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 630 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 660 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 690 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 720 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 750 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 780 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 810 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 840 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 870 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 900 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 930 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 960 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 990 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1020 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1050 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1080 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1110 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1140 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1170 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1200 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1230 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1260 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1290 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1320 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1350 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1380 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1410 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1440 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1470 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1500 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1530 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1560 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1590 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1620 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1650 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1680 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1710 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1740 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1770 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1800 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1830 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1860 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1890 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1920 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1950 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 1980 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2010 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2040 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2070 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2100 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2130 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2160 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2190 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2220 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2250 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2280 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2310 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2340 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2370 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2400 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2430 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2460 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2490 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2520 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2550 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2580 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2610 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2640 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2670 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2700 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2730 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2760 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2790 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2820 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2850 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2880 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2910 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2940 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 2970 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3000 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3030 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3060 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3090 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3120 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3150 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3180 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3210 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3240 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3270 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3300 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3330 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3360 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3390 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3420 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3450 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3480 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3510 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3540 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3570 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3600 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3630 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3660 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3690 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3720 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3750 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3780 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3810 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3840 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3870 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3900 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3930 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3960 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 3990 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4020 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4050 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4080 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4110 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4140 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4170 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4200 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4230 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4260 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4290 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4320 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4350 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4380 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4410 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4440 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4470 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4500 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4530 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4560 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4590 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4620 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4650 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4680 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4710 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4740 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4770 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4800 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4830 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4860 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4890 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4920 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4950 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 4980 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5010 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5040 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5070 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5100 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5130 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5160 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5190 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5220 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5250 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5280 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5310 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5340 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5370 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5400 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5430 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5460 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5490 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5520 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5550 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5580 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5610 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5640 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5670 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5700 个仓库\n",
            "请求成功，获取到 30 个仓库信息，当前已获取 5730 个仓库\n",
            "请求成功，获取到 20 个仓库信息，当前已获取 5750 个仓库\n",
            "已保存仓库信息到 ./data.json\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import requests\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import os\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# 替换为您的 GitHub 用户名和个人访问令牌\n",
        "username = userdata.get('GITHUB_NAME')\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "\n",
        "# GitHub API URL\n",
        "url = f'https://api.github.com/users/{username}/starred'\n",
        "headers = {\"Authorization\": f\"token {token}\"}\n",
        "\n",
        "# 初始化存储列表\n",
        "starred_repos = []\n",
        "\n",
        "# 先测试一次效果\n",
        "response = requests.get(url, headers=headers)\n",
        "if response.status_code == 200:\n",
        "    repos = response.json()\n",
        "    starred_repos.extend(repos)\n",
        "    # 输出调试信息\n",
        "    print(f\"第一次请求成功，获取到 {len(repos)} 个仓库信息\")\n",
        "    # 获取下一页的 URL（如果有）\n",
        "    url = response.links.get('next', {}).get('url')\n",
        "else:\n",
        "    print(f\"请求失败，状态码：{response.status_code}\")\n",
        "    url = None  # 停止循环\n",
        "\n",
        "# 循环读取所有分页的仓库数据\n",
        "while url:\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        repos = response.json()\n",
        "        starred_repos.extend(repos)\n",
        "        # 输出调试信息\n",
        "        print(f\"请求成功，获取到 {len(repos)} 个仓库信息，当前已获取 {len(starred_repos)} 个仓库\")\n",
        "        # 获取下一页的 URL（如果有）\n",
        "        url = response.links.get('next', {}).get('url')\n",
        "    else:\n",
        "        print(f\"请求失败，状态码：{response.status_code}\")\n",
        "        break\n",
        "\n",
        "# 保存到本地 star.md 文件\n",
        "with open('stars.md', 'w', encoding='utf-8') as file:\n",
        "    for repo in starred_repos:\n",
        "        name = repo['name']\n",
        "        description = repo['description'] or 'No description'\n",
        "        html_url = repo['html_url']\n",
        "        category = 'Unknown Category'  # 默认分类\n",
        "        tags = []  # 默认无标签\n",
        "        # 格式化写入\n",
        "        file.write(f\"- **Name**: {name}\\n\")\n",
        "        file.write(f\"  - **Description**: {description}\\n\")\n",
        "        file.write(f\"  - **URL**: {html_url}\\n\")\n",
        "        file.write(f\"  - **Category**: {category}\\n\")\n",
        "        file.write(f\"  - **Tags**: {tags}\\n\\n\")\n",
        "\n",
        "html_url = []\n",
        "for repo in starred_repos:\n",
        "    html_url.append({\"name\": repo['name'], \"url\": repo['html_url']})  # 使用 append 添加元素\n",
        "\n",
        "file_path = \"./data.json\"\n",
        "with open(file_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(html_url, f, indent=4, ensure_ascii=False)  # 将 html_url 写入文件\n",
        "print(f\"已保存仓库信息到 {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y iputils-ping\n"
      ],
      "metadata": {
        "id": "TinqfD8dS3uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ping google.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyi0JNDvSjrg",
        "outputId": "0a432b01-3848-498d-d4c1-9b5140837bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PING google.com (74.125.26.113) 56(84) bytes of data.\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=1 ttl=117 time=2.57 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=2 ttl=117 time=0.378 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=3 ttl=117 time=0.368 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=4 ttl=117 time=0.445 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=5 ttl=117 time=0.456 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=6 ttl=117 time=0.447 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=7 ttl=117 time=0.453 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=8 ttl=117 time=0.388 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=9 ttl=117 time=0.491 ms\n",
            "\n",
            "--- google.com ping statistics ---\n",
            "9 packets transmitted, 9 received, 0% packet loss, time 8012ms\n",
            "rtt min/avg/max/mdev = 0.368/0.665/2.565/0.672 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装gemeny"
      ],
      "metadata": {
        "id": "PVgDOQ-6Tvdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "NmmvuaWoTrto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-KMy3idO1od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import requests\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import os\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace(\"•\", \"  *\")\n",
        "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))\n",
        "\n",
        "\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "genai.configure(api_key=gemini_api_key)\n",
        "\n",
        "# for m in genai.list_models():\n",
        "#     if \"generateContent\" in m.supported_generation_methods:\n",
        "#         print(m.name)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "def generate_repo_info(repo_url):\n",
        "    \"\"\"使用 Gemini 生成 JSON 格式的描述、分类和标签。\n",
        "\n",
        "    Args:\n",
        "        repo_url: 仓库 URL。\n",
        "\n",
        "    Returns:\n",
        "        一个包含描述、分类和标签的字典，如果生成失败则返回 None。\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"请根据以下 GitHub 仓库链接生成 JSON 格式的描述、分类和标签：\n",
        "{repo_url}\n",
        "\n",
        "JSON 格式：\n",
        "{{\n",
        "  \"description\": \"仓库描述\",\n",
        "  \"category\": \"仓库分类\",\n",
        "  \"tags\": [\"标签1\", \"标签2\", ...]\n",
        "}}\n",
        "\"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    try:\n",
        "        # 使用 strip() 去除空白字符\n",
        "        # print(f\"Gemini API 返回的 JSON 数据：{response.text}\")\n",
        "        res_text=response.text.replace(\"```json\", \"\")\n",
        "        res_text=res_text.replace(\"```\", \"\")\n",
        "        # print(f\"JSON 数据：{res_text}\")\n",
        "        repo_info = json.loads(res_text.strip())\n",
        "        return repo_info\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"无法解析 Gemini 返回的 JSON 数据：{response.text}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "file_path=\"./data.json\"\n",
        "# 读取 stars.md 文件并更新信息\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    jsonData = json.load(f)\n",
        "\n",
        "\n",
        "updated_lines = []\n",
        "processed_count = 0  # 记录已处理的仓库数量\n",
        "\n",
        "# json_dir = './json'\n",
        "# for filename in os.listdir(json_dir):\n",
        "#     json_path = os.path.join(json_dir, filename)\n",
        "#     if os.path.isfile(json_path):  # 确保它是一个文件而不是目录\n",
        "#         os.remove(json_path)\n",
        "#         print(f\"已删除文件: {json_path}\")\n",
        "\n",
        "# 循环处理所有仓库\n",
        "for item in jsonData:\n",
        "    name = item['name']\n",
        "    url = item['url']\n",
        "    # 使用 Gemini 生成仓库信息\n",
        "    print(f\"Name: {name}, URL: {url}\")\n",
        "    onefile = f\"./json/{name}.json\"\n",
        "    if os.path.isfile(onefile):\n",
        "      print(f\"文件已存在，跳过：{onefile}\")\n",
        "      continue\n",
        "    else:\n",
        "      print(f\"获取git conten：{onefile}\")\n",
        "      repo_info = generate_repo_info(item['url'])\n",
        "      print(f\"repo_info {repo_info}\")\n",
        "\n",
        "      if repo_info:\n",
        "\n",
        "        with open(onefile, 'w', encoding='utf-8') as f:\n",
        "          json.dump(html_url, f, indent=4, ensure_ascii=False)\n",
        "        print(f\"已保存仓库信息到 {onefile}\")\n",
        "        # break\n",
        "        # 更新描述、分类和标签\n",
        "        updated_lines.append(f\"- **Name**: {name}\\n\")\n",
        "        updated_lines.append(f\"  - **Description**: {repo_info['description']}\\n\")\n",
        "        updated_lines.append(f\"  - **URL**: {url}\\n\")\n",
        "        updated_lines.append(f\"  - **Category**: {repo_info['category']}\\n\")\n",
        "        updated_lines.append(f\"  - **Tags**: {repo_info['tags']}\\n\\n\")\n",
        "        processed_count += 1\n",
        "        print(f\"已处理 {processed_count} 个仓库，当前仓库：{name}\")\n",
        "        time.sleep(2)\n",
        "        # break\n",
        "      else:\n",
        "        # 如果 Gemini 生成信息失败，保留原始行\n",
        "        updated_lines.append(f\"- **Name**: {name}\\n\")\n",
        "        updated_lines.append(f\"  - **URL**: {url}\\n\")\n",
        "\n",
        "        print(f\"Gemini 生成信息失败，跳过仓库：{name}\")\n",
        "\n",
        "    # break  # 仅处理第一个仓库，用于测试\n",
        "\n",
        "# 将更新后的内容写回 stars.md 文件\n",
        "with open('./new_stars.md', 'w', encoding='utf-8') as file:\n",
        "    file.writelines(updated_lines)\n",
        "\n",
        "print('new_stars.md 文件更新成功！')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BntNV_UJTu-l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae9ab8d2-009c-4af5-d0bf-06b45a9f98ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: starred, URL: https://github.com/maguowei/starred\n",
            "文件已存在，跳过：./json/starred.json\n",
            "Name: laravel-scout-opensearch, URL: https://github.com/zingimmick/laravel-scout-opensearch\n",
            "文件已存在，跳过：./json/laravel-scout-opensearch.json\n",
            "Name: nlp_paper_study, URL: https://github.com/km1994/nlp_paper_study\n",
            "文件已存在，跳过：./json/nlp_paper_study.json\n",
            "Name: WebChat, URL: https://github.com/molvqingtai/WebChat\n",
            "文件已存在，跳过：./json/WebChat.json\n",
            "Name: web-reader, URL: https://github.com/capjamesg/web-reader\n",
            "文件已存在，跳过：./json/web-reader.json\n",
            "Name: tweakphp, URL: https://github.com/tweakphp/tweakphp\n",
            "文件已存在，跳过：./json/tweakphp.json\n",
            "Name: languine, URL: https://github.com/midday-ai/languine\n",
            "文件已存在，跳过：./json/languine.json\n",
            "Name: chinese_sentiment, URL: https://github.com/linguishi/chinese_sentiment\n",
            "文件已存在，跳过：./json/chinese_sentiment.json\n",
            "Name: payload-oauth2, URL: https://github.com/WilsonLe/payload-oauth2\n",
            "文件已存在，跳过：./json/payload-oauth2.json\n",
            "Name: text-classification-cnn-rnn, URL: https://github.com/gaussic/text-classification-cnn-rnn\n",
            "文件已存在，跳过：./json/text-classification-cnn-rnn.json\n",
            "Name: browser-use, URL: https://github.com/browser-use/browser-use\n",
            "文件已存在，跳过：./json/browser-use.json\n",
            "Name: ai-hedge-fund, URL: https://github.com/virattt/ai-hedge-fund\n",
            "文件已存在，跳过：./json/ai-hedge-fund.json\n",
            "Name: hoarder, URL: https://github.com/hoarder-app/hoarder\n",
            "文件已存在，跳过：./json/hoarder.json\n",
            "Name: vercel-api-proxy, URL: https://github.com/souying/vercel-api-proxy\n",
            "文件已存在，跳过：./json/vercel-api-proxy.json\n",
            "Name: MachineLearning_Python, URL: https://github.com/lawlite19/MachineLearning_Python\n",
            "文件已存在，跳过：./json/MachineLearning_Python.json\n",
            "Name: tlbook-code, URL: https://github.com/jindongwang/tlbook-code\n",
            "文件已存在，跳过：./json/tlbook-code.json\n",
            "Name: pumpkin-book, URL: https://github.com/datawhalechina/pumpkin-book\n",
            "文件已存在，跳过：./json/pumpkin-book.json\n",
            "Name: revideo, URL: https://github.com/redotvideo/revideo\n",
            "文件已存在，跳过：./json/revideo.json\n",
            "Name: GenAI_Agents, URL: https://github.com/NirDiamant/GenAI_Agents\n",
            "文件已存在，跳过：./json/GenAI_Agents.json\n",
            "Name: element-plus, URL: https://github.com/element-plus/element-plus\n",
            "文件已存在，跳过：./json/element-plus.json\n",
            "Name: WeChat.CRM.SDK, URL: https://github.com/wuliaokankan/WeChat.CRM.SDK\n",
            "文件已存在，跳过：./json/WeChat.CRM.SDK.json\n",
            "Name: chainlit, URL: https://github.com/Chainlit/chainlit\n",
            "文件已存在，跳过：./json/chainlit.json\n",
            "Name: elasticvue, URL: https://github.com/cars10/elasticvue\n",
            "文件已存在，跳过：./json/elasticvue.json\n",
            "Name: bless-network-bot, URL: https://github.com/web3bothub/bless-network-bot\n",
            "文件已存在，跳过：./json/bless-network-bot.json\n",
            "Name: mit-18.06-linalg-notes, URL: https://github.com/apachecn/mit-18.06-linalg-notes\n",
            "文件已存在，跳过：./json/mit-18.06-linalg-notes.json\n",
            "Name: go-cursor-help, URL: https://github.com/yuaotian/go-cursor-help\n",
            "文件已存在，跳过：./json/go-cursor-help.json\n",
            "Name: MIT-Linear-Algebra-Notes, URL: https://github.com/MLNLP-World/MIT-Linear-Algebra-Notes\n",
            "文件已存在，跳过：./json/MIT-Linear-Algebra-Notes.json\n",
            "Name: doodleNet, URL: https://github.com/yining1023/doodleNet\n",
            "文件已存在，跳过：./json/doodleNet.json\n",
            "Name: filament-types, URL: https://github.com/tomatophp/filament-types\n",
            "文件已存在，跳过：./json/filament-types.json\n",
            "Name: bg-remove, URL: https://github.com/addyosmani/bg-remove\n",
            "文件已存在，跳过：./json/bg-remove.json\n",
            "Name: vis-three, URL: https://github.com/vis-three/vis-three\n",
            "文件已存在，跳过：./json/vis-three.json\n",
            "Name: Information-Extraction-Chinese, URL: https://github.com/crownpku/Information-Extraction-Chinese\n",
            "文件已存在，跳过：./json/Information-Extraction-Chinese.json\n",
            "Name: bert-chinese-ner, URL: https://github.com/ProHiryu/bert-chinese-ner\n",
            "文件已存在，跳过：./json/bert-chinese-ner.json\n",
            "Name: CosyVoice, URL: https://github.com/FunAudioLLM/CosyVoice\n",
            "文件已存在，跳过：./json/CosyVoice.json\n",
            "Name: Deep-Learning-21-Examples, URL: https://github.com/hzy46/Deep-Learning-21-Examples\n",
            "文件已存在，跳过：./json/Deep-Learning-21-Examples.json\n",
            "Name: daily-interview, URL: https://github.com/datawhalechina/daily-interview\n",
            "文件已存在，跳过：./json/daily-interview.json\n",
            "Name: laravel-db-snapshots, URL: https://github.com/spatie/laravel-db-snapshots\n",
            "获取git conten：./json/laravel-db-snapshots.json\n",
            "repo_info {'description': 'Easily create and restore database snapshots for your Laravel application.', 'category': 'Laravel Package', 'tags': ['laravel', 'database', 'snapshot', 'backup', 'restore', 'php', 'artisan', 'devops', 'database-backup', 'database-restore']}\n",
            "已保存仓库信息到 ./json/laravel-db-snapshots.json\n",
            "已处理 1 个仓库，当前仓库：laravel-db-snapshots\n",
            "Name: markitdown, URL: https://github.com/microsoft/markitdown\n",
            "获取git conten：./json/markitdown.json\n",
            "repo_info {'description': 'MarkItDown is a rich text editor for Markdown, designed to enhance the Markdown editing experience with features like syntax highlighting, autocompletion, and a live preview.', 'category': 'Text Editor', 'tags': ['Markdown', 'Editor', 'Rich Text Editor', 'Syntax Highlighting', 'Autocompletion', 'Live Preview', 'Microsoft', 'Web Development', 'JavaScript', 'React', 'TypeScript']}\n",
            "已保存仓库信息到 ./json/markitdown.json\n",
            "已处理 2 个仓库，当前仓库：markitdown\n",
            "Name: AnimatedDrawings, URL: https://github.com/facebookresearch/AnimatedDrawings\n",
            "获取git conten：./json/AnimatedDrawings.json\n",
            "repo_info {'description': 'This repository contains the code and data for the paper \"AnimatedDrawings: A Large-Scale Dataset of Human-Drawn Animations\".  It provides a large dataset of human-drawn animations, along with tools for data processing and evaluation of animation generation models. The dataset is diverse, encompassing a wide range of drawing styles and animation techniques.', 'category': 'Computer Vision, Machine Learning, Artificial Intelligence, Animation, Dataset', 'tags': ['animation', 'dataset', 'computer vision', 'machine learning', 'deep learning', 'pytorch', 'python', 'animation generation', 'human-drawn animation', 'large-scale dataset', 'facebook research', 'ai', 'neural network', 'data processing', 'model evaluation']}\n",
            "已保存仓库信息到 ./json/AnimatedDrawings.json\n",
            "已处理 3 个仓库，当前仓库：AnimatedDrawings\n",
            "Name: opentelemetry-collector, URL: https://github.com/open-telemetry/opentelemetry-collector\n",
            "获取git conten：./json/opentelemetry-collector.json\n",
            "repo_info {'description': \"OpenTelemetry Collector is a vendor-neutral implementation of the OpenTelemetry specification.  It receives telemetry data from various sources, processes it, and exports it to various backends. It's a central component in OpenTelemetry's architecture, enabling flexible and scalable observability solutions.\", 'category': 'Observability', 'tags': ['OpenTelemetry', 'Collector', 'Telemetry', 'Observability', 'Monitoring', 'Tracing', 'Metrics', 'Logging', 'Go', 'Data Processing', 'Agent', 'Instrumentation', 'Distributed Tracing', 'Vendor Neutral']}\n",
            "已保存仓库信息到 ./json/opentelemetry-collector.json\n",
            "已处理 4 个仓库，当前仓库：opentelemetry-collector\n",
            "Name: TEN-Agent, URL: https://github.com/TEN-framework/TEN-Agent\n",
            "获取git conten：./json/TEN-Agent.json\n",
            "repo_info {'description': \"TEN-Agent is a highly efficient and scalable large language model (LLM) agent framework built upon LangChain. It offers a modular design for easy customization and extension, enabling developers to rapidly build and deploy intelligent agents for various tasks.  Key features include efficient task planning, memory management, and flexible execution strategies.  It's designed for both research and production use cases.\", 'category': 'Artificial Intelligence/Machine Learning', 'tags': ['LLM', 'LangChain', 'Agent', 'Large Language Model', 'AI', 'Machine Learning', 'Framework', 'Python', 'Task Planning', 'Memory Management', 'Scalable', 'Efficient', 'Modular', 'Open Source']}\n",
            "已保存仓库信息到 ./json/TEN-Agent.json\n",
            "已处理 5 个仓库，当前仓库：TEN-Agent\n",
            "Name: laravel-elasticsearch, URL: https://github.com/pdphilip/laravel-elasticsearch\n",
            "获取git conten：./json/laravel-elasticsearch.json\n",
            "repo_info {'description': 'Laravel Elasticsearch package provides a simple way to interact with Elasticsearch from your Laravel applications. It supports indexing, searching, and deleting documents.  It offers features like fluent query builder, aggregation support, and scroll API for efficient data retrieval.', 'category': 'Laravel Package', 'tags': ['laravel', 'elasticsearch', 'php', 'search', 'indexing', 'full-text-search', 'laravel-package', 'elastic', 'database', 'query-builder', 'aggregation']}\n",
            "已保存仓库信息到 ./json/laravel-elasticsearch.json\n",
            "已处理 6 个仓库，当前仓库：laravel-elasticsearch\n",
            "Name: whiteboard, URL: https://github.com/mpociot/whiteboard\n",
            "获取git conten：./json/whiteboard.json\n",
            "repo_info {'description': 'A simple, self-hosted, and collaborative whiteboard.', 'category': 'Web Application', 'tags': ['whiteboard', 'collaborative', 'real-time', 'self-hosted', 'websockets', 'laravel', 'php', 'javascript', 'vue.js', 'open-source', 'online whiteboard']}\n",
            "已保存仓库信息到 ./json/whiteboard.json\n",
            "已处理 7 个仓库，当前仓库：whiteboard\n",
            "Name: fitlog, URL: https://github.com/fastnlp/fitlog\n",
            "获取git conten：./json/fitlog.json\n",
            "repo_info {'description': 'Fitlog is a lightweight and easy-to-use logging library for machine learning experiments. It supports various logging backends, including TensorBoard, WandB, and local file storage, and provides convenient functionalities for tracking metrics, parameters, and visualizations.', 'category': 'Machine Learning', 'tags': ['logging', 'machine learning', 'experiment tracking', 'tensorboard', 'wandb', 'python', 'library', 'metrics', 'visualization', 'parameter tracking', 'deep learning', 'pytorch', 'tensorflow']}\n",
            "已保存仓库信息到 ./json/fitlog.json\n",
            "已处理 8 个仓库，当前仓库：fitlog\n",
            "Name: multimodal-live-api-web-console, URL: https://github.com/google-gemini/multimodal-live-api-web-console\n",
            "获取git conten：./json/multimodal-live-api-web-console.json\n",
            "repo_info {'description': 'A web console for interacting with the Gemini Multimodal Live API.', 'category': 'Web Application, API Client, Google Gemini, Multimodal AI', 'tags': ['Google Gemini', 'Multimodal AI', 'API', 'Web Console', 'Live API', 'Web Application', 'JavaScript', 'React', 'Frontend', 'Client', 'Google', 'Gemini API', 'Multimodal', 'Live', 'Interactive']}\n",
            "已保存仓库信息到 ./json/multimodal-live-api-web-console.json\n",
            "已处理 9 个仓库，当前仓库：multimodal-live-api-web-console\n"
          ]
        }
      ]
    }
  ]
}