{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lpVdHQ-KfQf",
        "outputId": "b3ee71dd-6dcc-4860-9942-4d9550596bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "star.md 文件生成成功！\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# GitHub API URL\n",
        "url = f'https://api.github.com/users/{username}/starred'\n",
        "headers = {\"Authorization\": f\"token {token}\"}\n",
        "\n",
        "# 初始化存储列表\n",
        "starred_repos = []\n",
        "\n",
        "# 先测试一次效果\n",
        "response = requests.get(url, headers=headers)\n",
        "if response.status_code == 200:\n",
        "    repos = response.json()\n",
        "    starred_repos.extend(repos)\n",
        "    # 输出调试信息\n",
        "    print(f\"第一次请求成功，获取到 {len(repos)} 个仓库信息\")\n",
        "    # 获取下一页的 URL（如果有）\n",
        "    url = response.links.get('next', {}).get('url')\n",
        "else:\n",
        "    print(f\"请求失败，状态码：{response.status_code}\")\n",
        "    url = None  # 停止循环\n",
        "\n",
        "# 循环读取所有分页的仓库数据\n",
        "while url:\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        repos = response.json()\n",
        "        starred_repos.extend(repos)\n",
        "        # 输出调试信息\n",
        "        print(f\"请求成功，获取到 {len(repos)} 个仓库信息，当前已获取 {len(starred_repos)} 个仓库\")\n",
        "        # 获取下一页的 URL（如果有）\n",
        "        url = response.links.get('next', {}).get('url')\n",
        "    else:\n",
        "        print(f\"请求失败，状态码：{response.status_code}\")\n",
        "        break\n",
        "\n",
        "# 保存到本地 star.md 文件\n",
        "with open('stars.md', 'w', encoding='utf-8') as file:\n",
        "    for repo in starred_repos:\n",
        "        name = repo['name']\n",
        "        description = repo['description'] or 'No description'\n",
        "        html_url = repo['html_url']\n",
        "        category = 'Unknown Category'  # 默认分类\n",
        "        tags = []  # 默认无标签\n",
        "        # 格式化写入\n",
        "        file.write(f\"- **Name**: {name}\\n\")\n",
        "        file.write(f\"  - **Description**: {description}\\n\")\n",
        "        file.write(f\"  - **URL**: {html_url}\\n\")\n",
        "        file.write(f\"  - **Category**: {category}\\n\")\n",
        "        file.write(f\"  - **Tags**: {tags}\\n\\n\")\n",
        "\n",
        "print('star.md 文件生成成功！')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhh4LkHGS0uv",
        "outputId": "021dcbe6-848a-4e0a-d10f-5107f6b2b24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Waiting for headers] [1 InRelease 0 B/3,626 \r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Waiting for headers] [Waiting for headers] [\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Waiting for headers] [Waiting for headers] [\r                                                                                                    \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,630 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,566 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,448 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,517 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,517 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,830 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,614 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Fetched 26.9 MB in 3s (8,925 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y iputils-ping\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TinqfD8dS3uY",
        "outputId": "3c1cf8e6-cb1e-457f-90cc-dd962b5c6f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  iputils-ping\n",
            "0 upgraded, 1 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 42.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 iputils-ping amd64 3:20211215-1 [42.9 kB]\n",
            "Fetched 42.9 kB in 0s (126 kB/s)\n",
            "Selecting previously unselected package iputils-ping.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../iputils-ping_3%3a20211215-1_amd64.deb ...\n",
            "Unpacking iputils-ping (3:20211215-1) ...\n",
            "Setting up iputils-ping (3:20211215-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ping google.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyi0JNDvSjrg",
        "outputId": "0a432b01-3848-498d-d4c1-9b5140837bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PING google.com (74.125.26.113) 56(84) bytes of data.\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=1 ttl=117 time=2.57 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=2 ttl=117 time=0.378 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=3 ttl=117 time=0.368 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=4 ttl=117 time=0.445 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=5 ttl=117 time=0.456 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=6 ttl=117 time=0.447 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=7 ttl=117 time=0.453 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=8 ttl=117 time=0.388 ms\n",
            "64 bytes from vh-in-f113.1e100.net (74.125.26.113): icmp_seq=9 ttl=117 time=0.491 ms\n",
            "\n",
            "--- google.com ping statistics ---\n",
            "9 packets transmitted, 9 received, 0% packet loss, time 8012ms\n",
            "rtt min/avg/max/mdev = 0.368/0.665/2.565/0.672 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装gemeny"
      ],
      "metadata": {
        "id": "PVgDOQ-6Tvdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "NmmvuaWoTrto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-KMy3idO1od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import requests\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import os\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "\n",
        "# 替换为您的 GitHub 用户名和个人访问令牌\n",
        "username = userdata.get('GITHUB_NAME')\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace(\"•\", \"  *\")\n",
        "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "genai.configure(api_key=gemini_api_key)\n",
        "\n",
        "# for m in genai.list_models():\n",
        "#     if \"generateContent\" in m.supported_generation_methods:\n",
        "#         print(m.name)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "def generate_repo_info(repo_url):\n",
        "    \"\"\"使用 Gemini 生成 JSON 格式的描述、分类和标签。\n",
        "\n",
        "    Args:\n",
        "        repo_url: 仓库 URL。\n",
        "\n",
        "    Returns:\n",
        "        一个包含描述、分类和标签的字典，如果生成失败则返回 None。\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"请根据以下 GitHub 仓库链接生成 JSON 格式的描述、分类和标签：\n",
        "{repo_url}\n",
        "\n",
        "JSON 格式：\n",
        "{{\n",
        "  \"description\": \"仓库描述\",\n",
        "  \"category\": \"仓库分类\",\n",
        "  \"tags\": [\"标签1\", \"标签2\", ...]\n",
        "}}\n",
        "\"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    try:\n",
        "        # 使用 strip() 去除空白字符\n",
        "        # print(f\"Gemini API 返回的 JSON 数据：{response.text}\")\n",
        "        res_text=response.text.replace(\"```json\", \"\")\n",
        "        res_text=res_text.replace(\"```\", \"\")\n",
        "        # print(f\"JSON 数据：{res_text}\")\n",
        "        repo_info = json.loads(res_text.strip())\n",
        "        return repo_info\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"无法解析 Gemini 返回的 JSON 数据：{response.text}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 读取 stars.md 文件并更新信息\n",
        "with open('stars.md', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "    lines_iterator = iter(lines)\n",
        "\n",
        "updated_lines = []\n",
        "processed_count = 0  # 记录已处理的仓库数量\n",
        "# 循环处理所有仓库\n",
        "lines_iterator = iter(lines)\n",
        "for line in lines:\n",
        "    if line.startswith(\"- **Name**:\"):\n",
        "        name = line.replace(\"- **Name**:\",\"\")\n",
        "        file_path = f\"{name}.json\"   # 替换为你的文件路径\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"文件 {file_path} 已存在，跳过\")\n",
        "        else:\n",
        "            # 文件不存在，执行你的操作\n",
        "          print(f\"文件 {file_path} 不存在，开始处理\")\n",
        "\n",
        "          url_line = next(lines_iterator, None)  # 读取下一行获取 URL\n",
        "          print(f\"url_line {url_line}\")\n",
        "          if url_line and url_line.startswith(\"  - **URL**:\"):\n",
        "              print(f\"url_line {url_line}\")\n",
        "              repo_url = url_line.replace(\"  - **URL**:\",\"\")\n",
        "              print(f\"url_line {url_line}\")\n",
        "              # 使用 Gemini 生成仓库信息\n",
        "              repo_info = generate_repo_info(repo_url)\n",
        "              print(f\"repo_info {repo_info}\")\n",
        "\n",
        "              if repo_info:\n",
        "                  filename = f\"{name}.json\"  # 使用仓库名称作为文件名\n",
        "                  print(f\"filename {filename}\")\n",
        "                  with open(filename, 'w', encoding='utf-8') as f:\n",
        "                      json.dump(repo_info, f, indent=4, ensure_ascii=False)\n",
        "                  print(f\"已保存仓库信息到 {filename}\")\n",
        "\n",
        "                  # # 更新描述、分类和标签\n",
        "                  updated_lines.append(line)\n",
        "                  updated_lines.append(f\"  - **Description**: {repo_info['description']}\\n\")\n",
        "                  updated_lines.append(f\"  - **URL**: {repo_url}\\n\")\n",
        "                  updated_lines.append(f\"  - **Category**: {repo_info['category']}\\n\")\n",
        "                  updated_lines.append(f\"  - **Tags**: {repo_info['tags']}\\n\\n\")\n",
        "                  processed_count += 1\n",
        "                  print(f\"已处理 {processed_count} 个仓库，当前仓库：{name}\")\n",
        "                  time.sleep(1)\n",
        "                  # break\n",
        "              else:\n",
        "                  # 如果 Gemini 生成信息失败，保留原始行\n",
        "                  updated_lines.append(line)\n",
        "                  updated_lines.append(url_line)\n",
        "                  print(f\"Gemini 生成信息失败，跳过仓库：{name}\")\n",
        "          else:\n",
        "              updated_lines.append(line)\n",
        "    else:\n",
        "        updated_lines.append(line)\n",
        "\n",
        "    # break  # 仅处理第一个仓库，用于测试\n",
        "\n",
        "# 将更新后的内容写回 stars.md 文件\n",
        "with open('new_stars.md', 'w', encoding='utf-8') as file:\n",
        "    file.writelines(updated_lines)\n",
        "\n",
        "print('new_stars.md 文件更新成功！')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BntNV_UJTu-l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8150311b-4fb0-457b-c773-7766b15e2004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "文件  starred\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: starred\n",
            "\n",
            "文件  laravel-scout-opensearch\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: creating your own Awesome List by GitHub stars!\n",
            "\n",
            "文件  nlp_paper_study\n",
            ".json 已存在，跳过\n",
            "文件  WebChat\n",
            ".json 已存在，跳过\n",
            "文件  web-reader\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/maguowei/starred\n",
            "\n",
            "url_line   - **URL**: https://github.com/maguowei/starred\n",
            "\n",
            "url_line   - **URL**: https://github.com/maguowei/starred\n",
            "\n",
            "repo_info {'description': \"This repository is a list of GitHub repositories I've starred.  It's a personal collection and doesn't necessarily represent a curated or organized list of projects.\", 'category': 'Personal Collection', 'tags': ['starred', 'github', 'personal', 'collection', 'repositories', 'bookmarks']}\n",
            "filename  web-reader\n",
            ".json\n",
            "已保存仓库信息到  web-reader\n",
            ".json\n",
            "已处理 1 个仓库，当前仓库： web-reader\n",
            "\n",
            "文件  tweakphp\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  languine\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  chinese_sentiment\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  payload-oauth2\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: laravel-scout-opensearch\n",
            "\n",
            "文件  text-classification-cnn-rnn\n",
            ".json 已存在，跳过\n",
            "文件  browser-use\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: Laravel Scout custom engine for OpenSearch\n",
            "\n",
            "文件  ai-hedge-fund\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/zingimmick/laravel-scout-opensearch\n",
            "\n",
            "url_line   - **URL**: https://github.com/zingimmick/laravel-scout-opensearch\n",
            "\n",
            "url_line   - **URL**: https://github.com/zingimmick/laravel-scout-opensearch\n",
            "\n",
            "repo_info {'description': 'Laravel Scout driver for OpenSearch.  This package provides a driver for the Laravel Scout search engine using OpenSearch.', 'category': 'Laravel Package, Search Engine, OpenSearch', 'tags': ['laravel', 'scout', 'opensearch', 'search', 'elasticsearch', 'fulltext-search', 'php', 'driver', 'laravel-package', 'opensource']}\n",
            "filename  ai-hedge-fund\n",
            ".json\n",
            "已保存仓库信息到  ai-hedge-fund\n",
            ".json\n",
            "已处理 2 个仓库，当前仓库： ai-hedge-fund\n",
            "\n",
            "文件  hoarder\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  vercel-api-proxy\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  MachineLearning_Python\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  tlbook-code\n",
            ".json 已存在，跳过\n",
            "文件  pumpkin-book\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: nlp_paper_study\n",
            "\n",
            "文件  revideo\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: 该仓库主要记录 NLP 算法工程师相关的顶会论文研读笔记\n",
            "\n",
            "文件  GenAI_Agents\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/km1994/nlp_paper_study\n",
            "\n",
            "url_line   - **URL**: https://github.com/km1994/nlp_paper_study\n",
            "\n",
            "url_line   - **URL**: https://github.com/km1994/nlp_paper_study\n",
            "\n",
            "repo_info {'description': \"This repository contains my personal notes and code for NLP papers I've studied.  It's organized by paper, with each folder containing relevant notes, code implementations, and sometimes experimental results.\", 'category': 'Natural Language Processing (NLP), Research, Paper Study, Code Implementation', 'tags': ['NLP', 'Natural Language Processing', 'Paper Review', 'Paper Summary', 'Research Notes', 'Deep Learning', 'Machine Learning', 'Code', 'Python', 'PyTorch', 'TensorFlow', 'Transformers', 'BERT', 'GPT', 'Language Models', 'Notebooks', 'Jupyter Notebook']}\n",
            "filename  GenAI_Agents\n",
            ".json\n",
            "已保存仓库信息到  GenAI_Agents\n",
            ".json\n",
            "已处理 3 个仓库，当前仓库： GenAI_Agents\n",
            "\n",
            "文件  element-plus\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  WeChat.CRM.SDK\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  chainlit\n",
            ".json 已存在，跳过\n",
            "文件  elasticvue\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  bless-network-bot\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: WebChat\n",
            "\n",
            "文件  mit-18.06-linalg-notes\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: 💬 Chat with anyone on any website.\n",
            "\n",
            "文件  go-cursor-help\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/molvqingtai/WebChat\n",
            "\n",
            "url_line   - **URL**: https://github.com/molvqingtai/WebChat\n",
            "\n",
            "url_line   - **URL**: https://github.com/molvqingtai/WebChat\n",
            "\n",
            "repo_info {'description': '一个基于 Vue.js 的 WebChat 组件库，提供简洁易用的聊天界面和丰富的功能，方便开发者快速构建自己的在线聊天应用。', 'category': 'Web 开发', 'tags': ['Vue.js', 'WebChat', '聊天组件', '前端组件库', '在线聊天', 'JavaScript', 'UI组件', 'Vue', '组件库', 'web开发']}\n",
            "filename  go-cursor-help\n",
            ".json\n",
            "已保存仓库信息到  go-cursor-help\n",
            ".json\n",
            "已处理 4 个仓库，当前仓库： go-cursor-help\n",
            "\n",
            "文件  MIT-Linear-Algebra-Notes\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  doodleNet\n",
            ".json 已存在，跳过\n",
            "文件  filament-types\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  bg-remove\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  vis-three\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: web-reader\n",
            "\n",
            "文件  Information-Extraction-Chinese\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: A minimal web reader.\n",
            "\n",
            "文件  bert-chinese-ner\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/capjamesg/web-reader\n",
            "\n",
            "url_line   - **URL**: https://github.com/capjamesg/web-reader\n",
            "\n",
            "url_line   - **URL**: https://github.com/capjamesg/web-reader\n",
            "\n",
            "repo_info {'description': 'A minimal, distraction-free web reader built with React.', 'category': 'Web Development', 'tags': ['React', 'web reader', 'minimal', 'distraction-free', 'JavaScript', 'frontend', 'reading', 'web app', 'single page application']}\n",
            "filename  bert-chinese-ner\n",
            ".json\n",
            "已保存仓库信息到  bert-chinese-ner\n",
            ".json\n",
            "已处理 5 个仓库，当前仓库： bert-chinese-ner\n",
            "\n",
            "文件  CosyVoice\n",
            ".json 已存在，跳过\n",
            "文件  Deep-Learning-21-Examples\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  daily-interview\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  laravel-db-snapshots\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  markitdown\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: tweakphp\n",
            "\n",
            "文件  AnimatedDrawings\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: Easily tweak your PHP code\n",
            "\n",
            "文件  opentelemetry-collector\n",
            ".json 已存在，跳过\n",
            "文件  TEN-Agent\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/tweakphp/tweakphp\n",
            "\n",
            "url_line   - **URL**: https://github.com/tweakphp/tweakphp\n",
            "\n",
            "url_line   - **URL**: https://github.com/tweakphp/tweakphp\n",
            "\n",
            "repo_info {'description': 'Tweak is a lightweight, highly customizable, and extensible PHP framework built for rapid development and easy maintenance.  It aims to provide a solid foundation for building robust web applications without imposing strict conventions or unnecessary complexity.', 'category': 'PHP Framework', 'tags': ['PHP', 'Framework', 'Lightweight', 'Customizable', 'Extensible', 'Rapid Development', 'MVC', 'Web Application', 'Open Source', 'Composer']}\n",
            "filename  TEN-Agent\n",
            ".json\n",
            "已保存仓库信息到  TEN-Agent\n",
            ".json\n",
            "已处理 6 个仓库，当前仓库： TEN-Agent\n",
            "\n",
            "文件  laravel-elasticsearch\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  whiteboard\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  fitlog\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  multimodal-live-api-web-console\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: languine\n",
            "\n",
            "文件  PDFMathTranslate\n",
            ".json 已存在，跳过\n",
            "文件  LocalAI\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: Translate your application with Languine CLI powered by AI.\n",
            "\n",
            "文件  jimeng-free-api\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/midday-ai/languine\n",
            "\n",
            "url_line   - **URL**: https://github.com/midday-ai/languine\n",
            "\n",
            "url_line   - **URL**: https://github.com/midday-ai/languine\n",
            "\n",
            "repo_info {'description': \"Languine is a lightweight, high-performance, and easy-to-use language model designed for local deployment. It's built on top of llama.cpp and offers various quantization techniques for efficient inference on resource-constrained devices.\", 'category': 'Machine Learning/Natural Language Processing', 'tags': ['language model', 'llama.cpp', 'quantization', 'local deployment', 'lightweight', 'high-performance', 'inference', 'NLP', 'LLM', 'open-source']}\n",
            "filename  jimeng-free-api\n",
            ".json\n",
            "已保存仓库信息到  jimeng-free-api\n",
            ".json\n",
            "已处理 7 个仓库，当前仓库： jimeng-free-api\n",
            "\n",
            "文件  fish-speech-gui\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  ee-core\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  electron-egg\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  MagicQuill\n",
            ".json 已存在，跳过\n",
            "文件  desktop\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: chinese_sentiment\n",
            "\n",
            "文件  RMBG-2.0\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: 中文情感分析，CNN，BI-LSTM，文本分类\n",
            "\n",
            "文件  rapidjson\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/linguishi/chinese_sentiment\n",
            "\n",
            "url_line   - **URL**: https://github.com/linguishi/chinese_sentiment\n",
            "\n",
            "url_line   - **URL**: https://github.com/linguishi/chinese_sentiment\n",
            "\n",
            "repo_info {'description': '一个中文情感分析工具包，包含多种预训练模型和工具函数，方便用户进行快速的情感分类和情感倾向分析。支持多种模型，包括基于词典的规则方法和基于深度学习的模型。', 'category': '自然语言处理', 'tags': ['中文情感分析', '自然语言处理', 'NLP', '情感分类', '情感倾向分析', '预训练模型', '深度学习', '机器学习', 'python', '工具包', '中文分词', '词典', '规则方法']}\n",
            "filename  rapidjson\n",
            ".json\n",
            "已保存仓库信息到  rapidjson\n",
            ".json\n",
            "已处理 8 个仓库，当前仓库： rapidjson\n",
            "\n",
            "文件  BitNet\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  wvp-GB28181-pro\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  VAR\n",
            ".json 已存在，跳过\n",
            "文件  pydantic-ai\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  open-notebooklm\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: payload-oauth2\n",
            "\n",
            "文件  AI_Tutorial\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: Plugin for PayloadCMS to integrate OAuth2\n",
            "\n",
            "文件  key-book\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/WilsonLe/payload-oauth2\n",
            "\n",
            "url_line   - **URL**: https://github.com/WilsonLe/payload-oauth2\n",
            "\n",
            "url_line   - **URL**: https://github.com/WilsonLe/payload-oauth2\n",
            "\n",
            "repo_info {'description': 'A simple OAuth 2.0 payload generator for testing and development purposes.  Supports various grant types and allows customization of the payload.', 'category': 'Developer Tools', 'tags': ['OAuth 2.0', 'OAuth2', 'Payload Generator', 'Testing', 'Development', 'JWT', 'Authorization Code', 'Client Credentials', 'Password Credentials', 'Refresh Token', 'Authorization Server', 'Security', 'Tools', 'Python']}\n",
            "filename  key-book\n",
            ".json\n",
            "已保存仓库信息到  key-book\n",
            ".json\n",
            "已处理 9 个仓库，当前仓库： key-book\n",
            "\n",
            "文件  SmsForwarder\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  llm_aided_ocr\n",
            ".json 已存在，跳过\n",
            "文件  revive-adserver\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  refine\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  markdown-extended\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: text-classification-cnn-rnn\n",
            "\n",
            "文件  NSmartProxy\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: CNN-RNN中文文本分类，基于TensorFlow\n",
            "\n",
            "文件  billd-live\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/gaussic/text-classification-cnn-rnn\n",
            "\n",
            "url_line   - **URL**: https://github.com/gaussic/text-classification-cnn-rnn\n",
            "\n",
            "url_line   - **URL**: https://github.com/gaussic/text-classification-cnn-rnn\n",
            "\n",
            "repo_info {'description': 'This repository contains a TensorFlow implementation of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for text classification.  It includes examples and tutorials to help you build and train your own text classification models.', 'category': 'Machine Learning', 'tags': ['text classification', 'CNN', 'RNN', 'TensorFlow', 'deep learning', 'natural language processing', 'NLP', 'machine learning', 'text processing', 'python', 'tutorial', 'example']}\n",
            "filename  billd-live\n",
            ".json\n",
            "已保存仓库信息到  billd-live\n",
            ".json\n",
            "已处理 10 个仓库，当前仓库： billd-live\n",
            "\n",
            "文件  pytorch-doc-zh\n",
            ".json 已存在，跳过\n",
            "文件  xiaozhi-esp32\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  apifm-wxapi\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  lms\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  CRUD\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: browser-use\n",
            "\n",
            "文件  translation-manager\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: Make websites accessible for AI agents\n",
            "\n",
            "文件  web-demuxer\n",
            ".json 已存在，跳过\n",
            "文件  puppet-wechat4u\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/browser-use/browser-use\n",
            "\n",
            "url_line   - **URL**: https://github.com/browser-use/browser-use\n",
            "\n",
            "url_line   - **URL**: https://github.com/browser-use/browser-use\n",
            "\n",
            "repo_info {'description': 'A constantly updated list of browser usage statistics, from StatCounter.', 'category': 'Data/Statistics', 'tags': ['browser', 'usage', 'statistics', 'statcounter', 'web', 'data', 'analytics', 'market share', 'browser share', 'javascript', 'browserslist']}\n",
            "filename  puppet-wechat4u\n",
            ".json\n",
            "已保存仓库信息到  puppet-wechat4u\n",
            ".json\n",
            "已处理 11 个仓库，当前仓库： puppet-wechat4u\n",
            "\n",
            "文件  aisuite\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  PhotoSwipe\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  wechat2tg\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  farmOS\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: ai-hedge-fund\n",
            "\n",
            "文件  go\n",
            ".json 已存在，跳过\n",
            "文件  SocialEngineeringDictionaryGenerator\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: An AI Hedge Fund Team\n",
            "\n",
            "文件  docker-tutorial\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/virattt/ai-hedge-fund\n",
            "\n",
            "url_line   - **URL**: https://github.com/virattt/ai-hedge-fund\n",
            "\n",
            "url_line   - **URL**: https://github.com/virattt/ai-hedge-fund\n",
            "\n",
            "repo_info {'description': 'A framework for building AI-powered hedge funds.  Includes tools and strategies for algorithmic trading, portfolio optimization, and risk management using machine learning.', 'category': 'Algorithmic Trading & Quantitative Finance', 'tags': ['AI', 'Algorithmic Trading', 'Hedge Fund', 'Machine Learning', 'Quantitative Finance', 'Portfolio Optimization', 'Risk Management', 'Python', 'Backtesting', 'Trading Strategies', 'Deep Learning', 'Reinforcement Learning']}\n",
            "filename  docker-tutorial\n",
            ".json\n",
            "已保存仓库信息到  docker-tutorial\n",
            ".json\n",
            "已处理 12 个仓库，当前仓库： docker-tutorial\n",
            "\n",
            "文件  FinnewsHunter\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Category**: Unknown Category\n",
            "\n",
            "文件  wubi-lex\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Tags**: []\n",
            "\n",
            "文件  encoding\n",
            ".json 不存在，开始处理\n",
            "url_line \n",
            "\n",
            "文件  time-series-analysis\n",
            ".json 已存在，跳过\n",
            "文件  all-of-statistics\n",
            ".json 不存在，开始处理\n",
            "url_line - **Name**: hoarder\n",
            "\n",
            "文件  passport\n",
            ".json 不存在，开始处理\n",
            "url_line   - **Description**: A self-hostable bookmark-everything app (links, notes and images) with AI-based automatic tagging and full text search\n",
            "\n",
            "文件  backtrace\n",
            ".json 不存在，开始处理\n",
            "url_line   - **URL**: https://github.com/hoarder-app/hoarder\n",
            "\n",
            "url_line   - **URL**: https://github.com/hoarder-app/hoarder\n",
            "\n",
            "url_line   - **URL**: https://github.com/hoarder-app/hoarder\n",
            "\n",
            "repo_info {'description': \"Hoarder is a free and open-source, cross-platform, self-hostable application for managing your digital collections.  It's designed to be easy to use, extensible, and customizable.\", 'category': 'Software Application', 'tags': ['self-hosted', 'open-source', 'collection management', 'database', 'cross-platform', 'digital asset management', 'media management', 'library management', 'Go', 'GUI', 'Electron', 'PostgreSQL', 'SQLite']}\n",
            "filename  backtrace\n",
            ".json\n",
            "已保存仓库信息到  backtrace\n",
            ".json\n",
            "已处理 13 个仓库，当前仓库： backtrace\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
